\documentclass[12pt, letterpaper]{article}
\usepackage[titletoc,title]{appendix}
\usepackage{booktabs}
\usepackage[margin=1in]{geometry}
\usepackage[linkcolor=blue,
			colorlinks=true,
			urlcolor=blue,
			pdfstartview={XYZ null null 1.00},
			pdfpagemode=UseNone,
			citecolor={black},
			pdftitle={blacklight}]{hyperref}

%\newcites{SI}{SI References}
\usepackage{natbib}
\usepackage{booktabs}
\usepackage{float}
\usepackage{placeins}

\usepackage{geometry}  % see geometry.pdf on how to lay out the page. There's lots.
\geometry{letterpaper} % This is 8.5x11 paper. Options are a4paper or a5paper or other...
\usepackage{graphicx}  % Handles inclusion of major graphics formats and allows use of
\usepackage{units}
\usepackage{amsfonts,amsmath,amsbsy}
\usepackage{amsxtra}
\usepackage{verbatim}
%\setcitestyle{round,semicolon,aysep={},yysep={;}}
\usepackage{setspace} % Permits line spacing control. Options are:
%\doublespacing
%\onehalfspace
%\usepackage{sectsty}    % Permits control of section header styles
\usepackage{pdflscape}
\usepackage{fancyhdr}   % Permits header customization. See header section below.
\usepackage{url}        % Correctly formats URLs with the \url{} tag
\usepackage{xurl}
\usepackage{fullpage}   %1-inch margins
\usepackage{multirow}
\usepackage{verbatim}
\usepackage{rotating}
\setlength{\parindent}{3em}

%\usepackage[T1]{fontenc}
%\usepackage[bitstream-charter]{mathdesign}

\usepackage{chngcntr}
\usepackage{longtable}
\usepackage{adjustbox}
\usepackage{dcolumn}
\usepackage{tabularx}

\usepackage{lineno}

\usepackage[12pt]{moresize}

\usepackage{pdfpages}

% https://tex.stackexchange.com/questions/611786/misplaced-noalign-because-input-before-booktabs-rule
% I was getting Misplaced \noalign. \bottomrule on my laptop
% but not on my desktop...
% Comment out for older LaTeX versions
%\iffalse
\ExplSyntaxOn
\cs_new:Npn \expandableinput #1
{ \use:c { @@input } { \file_full_name:n {#1} } }
\AddToHook{env/tabular/begin}
{ \cs_set_eq:NN \input \expandableinput }
\ExplSyntaxOff
%\fi


\usepackage[nameinlink, capitalize, noabbrev]{cleveref}

\def\citeapos#1{\citeauthor{#1}'s (\citeyear{#1})}

\makeatother

\usepackage{footmisc}
\setlength{\footnotesep}{\baselineskip}
\makeatother
\renewcommand{\footnotelayout}{\footnotesize \onehalfspacing}
%https://tex.stackexchange.com/a/68242
%prevent footnotes splitting over pages
\interfootnotelinepenalty=10000


% Colors
\usepackage{color}

\newcommand{\bch}{\color{blue}\em  }   % begin change
\newcommand{\ying} {\color{orange}\em  }   % begin change
\newcommand{\bgcd} {\color{purple}\em }
\newcommand{\ech}{\color{black}\rm  }    % end change

\newcommand{\note}[1]{\textcolor{orange}{#1}}

% Caption
% Caption
\usepackage[
    skip            =0pt,
    labelfont       =bf, 
    font            =small,
    textfont        =small,
    figurename      =Figure,
    justification   =justified,
    singlelinecheck =false,
    labelsep        =period]
{caption}
%\captionsetup[subtable]{font=small,skip=0pt}
\usepackage{subcaption}

% tt font issues
% \renewcommand*{\ttdefault}{qcr}
\renewcommand{\ttdefault}{pcr}

\usepackage{tocloft}

\newcommand{\detailtexcount}[1]{%
  \immediate\write18{texcount -merge -sum -q #1.tex output.bbl > #1.wcdetail }%
  \verbatiminput{#1.wcdetail}%
}

\newcommand{\quickwordcount}[1]{%
  \immediate\write18{texcount -1 -sum -merge -q #1.tex output.bbl > #1-words.sum }%
  \input{#1-words.sum} words%
}

\newcommand{\quickcharcount}[1]{%
  \immediate\write18{texcount -1 -sum -merge -char -q #1.tex output.bbl > #1-chars.sum }%
  \input{#1-chars.sum} characters (not including spaces)%
}

\title{Always--On Probability Calibration With Vectorized Multiplicative--Weights\thanks{\href{https://github.com/finite-sample/mw-calibration}{https://github.com/finite-sample/mw-calibration}.}}

\author{Gaurav Sood\thanks{Gaurav can be reached at \href{mailto:gsood07@gmail.com}{\footnotesize{\texttt{gsood07@gmail.com}}}}\vspace{.5cm}}

\date{\today}

\begin{document}


\maketitle

\begin{abstract}
We propose a solver-free, streaming approach to post-hoc probability calibration based on Multiplicative-Weights Updates (MWU).  Unlike standard Platt scaling or isotonic regression---which are trained in batch and periodically retrained offline---MWU performs a single exponential update per bucket or segment, requiring constant time per batch regardless of total traffic. Experiments on a synthetic ad-tech scenario with drift show that MWU matches the Brier score of classical calibrators while requiring $\mathbf{60\text{--}100\times}$ less compute when recalibrating every mini-batch.
\end{abstract}

\section{Introduction}
Probability calibration is critical in ads, recommendations, and risk models \citep{Niculescu05, Guo17}.  The dominant post-hoc techniques---Platt scaling \citep{Platt99} and isotonic regression \citep{Zadrozny02}---are trained in batch and periodically refit. In high-velocity settings, this creates a \emph{compute-drift trade-off}: infrequent retraining leads to miscalibration, whereas frequent retraining incurs heavy CPU costs.

We recast calibration as an online convex–concave game and apply the Multiplicative-Weights Update method (MWU) \citep{Arora12}. The result is an \emph{always-on} calibrator that adapts instantly to drift with constant per-batch cost.

\section{Problem Setup}
Given raw probabilities $p\_i^{\mathrm{raw}}$ and binary outcomes $y\_i\in{0,1}$,
let $b(i)\in{1,\dots,B}$ denote the reliability bucket for event $i$. We seek bias factors $c\_b>0$ such that calibrated probabilities:

$$p_i^{\mathrm{cal}} = \frac{c_{b(i)},p_i^{\mathrm{raw}}}
                              {1-p_i^{\mathrm{raw}}+c_{b(i)}\,p_i^{\mathrm{raw}}}
$$

are
(approximately) \emph{self--calibrated}:
$\hat{r}_b \approx \tilde{r}_b$ where $\hat{r}_b$ is the empirical click-through rate and $\tilde{r}_b$ the mean of $p^{\mathrm{cal}}$ in bucket $b$.

\section{Multiplicative-Weights Calibrator}
Let $\ell_b^{(t)} = \tilde{r}_b^{(t)} - \hat{r}_b^{(t)}$ be the calibration error for bucket $b$ in batch $t$. MWU performs
\begin{equation}
c_b^{(t+1)} = c_b^{(t)}\exp\left(-\eta \ell_b^{(t)}\right),
\label{eq:mwu}
\end{equation}
followed by clipping $c_b \in \left[c_{\min}, c_{\max}\right]$. Under standard assumptions, MWU enjoys an $\mathcal{O}(\sqrt{T})$ regret bound
\citep{Arora12}.

\section{Related Work}
\begin{itemize}
\item \textbf{Batch calibration.}  Platt \citep{Platt99} fits a logistic transform; isotonic regression uses the Pool-Adjacent-Violators (PAV) algorithm \citep{Zadrozny02}. More recent approaches include temperature scaling \citep{Guo17} and neural calibration heads \citep{Kull19}.

\item \textbf{Online calibration.}  Blackwell approachability methods \citep{Foster18} guarantee online calibration under adversarial sequences but require projections onto calibrated sets. Multiplicative-Weights updates have been used in universal portfolios \citep{Cover91} and fairness-constrained classification \citep{Agarwal18}, but— to our knowledge—have not been applied to streaming ad probability calibration.
\end{itemize}

\section{Experiments}
\subsection{Synthetic Ad-Tech Stream}
We simulate $200,\text{k}$ impressions in $40$ batches ($5,\text{k}$ each) with drift $\mu_t = 0.7 \cdot t/T$. Calibration buckets $B=100$.
We compare:
\begin{enumerate}
\item Platt (logistic),
\item Isotonic regression (PAV),
\item \textbf{MWU} (Eq.~\ref{eq:mwu}).
\end{enumerate}
All methods are recalibrated every batch.

\subsection{Results}
\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Metric & Platt & Isotonic & \textbf{MWU}\\\midrule
Mean per--batch Brier & \textbf{0.2051} & 0.2045 & 0.2052\\
Std.~~Brier            & 0.0019 & \textbf{0.0017} & 0.0019\\
Mean CPU~~s/batch      & 0.0243 & 0.0181 & \textbf{0.00039}\\\bottomrule
\end{tabular}
\caption{Accuracy and compute over 40 batches. MWU matches Brier performance while requiring $60\text{--}100\times$ less CPU.}
\label{tab:main}
\end{table}

\section{Discussion}
With per-batch refits, Platt/Isotonic deliver marginally lower Brier, but CPU load scales with cumulative traffic.  In realistic deployments, they are often retrained hourly, introducing calibration drift between jobs.  MWU removes this drift--compute trade-off: constant update cost and immediate correction.

\section{Conclusion}
MWU offers a lightweight, always-on alternative to batch calibration.  Future work includes adaptive learning-rate schedules and large-scale deployment studies on production ad traffic.

\bibliographystyle{apalike}
\bibliography{mwu}
\end{document}
